Small manual for HydroC
-----------------------

HydroC is an hybrid implementation (MPI + OpenMP).

To compile hydroc, adapt the Makefile to your local
installation. Normally, the different variables should be explicit
enough.

The current Makefile has the possibility to build hydroc with various
options (O is a shortcut for ON). Each architecture as its own
makefile (e.g. make.epyc) that is included by the master Makefile.

PG=O	    to use gprof profiling tool

MPI=O	    to create a MPI version (default node only version)


XHOST=O to build a tightly coupled binary to your local CPU, will get
an invalid instruction on a not compatible hardware.

MIC=O	    to produce a native version for the MIC (KNC)
AVX=O	    to force AVX usage
AVX2=O	    to force AVX2 usage (Haswell)
ATOM=O	    to force SSE4 for the atom
SSE=O	    to force SSE usage (Nehalem)
KNL=O	    to force MIC-AVX512 usage for the KNL
AVX3=O 	    to force Skylake code generation.
EPYC=O	    to compile for the Zen platform
THX2=O	    to compile for the ThunderX 2 armv8 platform

default value is to build for AVX2. 

PNG=O to produce PNG images (PPM otherwise). Images are forced to be
less than 2000 pixels wide so the program will shrink then if needed
(yet still compute the full nx x ny domain).

VERB=O	    for a verbose output of the vectorization

NOVEC=O to inhibit vectorization (for vectorization speedup
measurement)

so, 
    make MPI=O PNG=O AVX=O clean hydroc

will clean everything then build hydroc with MPI capability and AVX
optimization plus produce PNG images rather than PPM.


The make.runs file is there for convenience. The idea is to centralize
different run situations to make them easily accessible while
rebuilding the program. Thus: make MPI=O PNG=O AVX=O run will
recompile hydroc if necessary and start hydroc on a standard test
case.

The input file looks like this:

_______________________________________________________________
This namelist contains various input parameters for HYDRO runs

&RUN
tend=460
#tend=3
# noutput=1
nstepmax=20
# dtoutput=0.1
# dtimage=.2
# chkpt=1
/

&MESH
nx=6000
ny=6000
tilesize=60
morton=1
numa=1
tasked=   1
taskeddep=1
prt=0
dx=0.05
boundary_left=1
boundary_right=1
boundary_down=3
boundary_up=3
testcase=3
/

&HYDRO
courant_factor=0.8
niter_riemann=10
/
_______________________________________________________________


where lines beginning with a # are ignored.

Warning : Physical time is the (unitless) time of the physics
simulated here. It has nothing to do with the elaps time of the
computation.


Meaning of the keywords of interest:

tend = physical time at which the simulation should end. Might take a
couple of runs ;-)

nstepmax = maximum number of iterations for a single run

# driving the outputs
noutput = number of iterations between two VTK dumps
dtoutput = interval of physical time between two VTK dumps
dtimage = interval of physical time between two images (PNG or PPM)

chkpt = if not 0, produce a checkpoint file at the end of the run.

nx, ny = total size of the domain. An MPI run will divide those values
according to the number of tasks.

tilesize = the size of the side of a square] tile (excluding the ghost
cells). Typical values are 28 or 60. The value really depends on the
underlying architecture.

morton = if 1, the OpenMP threads will pick tiles according to a
morton curve.
numa = 1 if numaness has to be taken into account.
tasked = 1 to use a single task mechanism instead of omp parallel for
taskeddep = 1 a more elaborate task mechanism that takes tile dependencies into account

prt = if 1, print all arrays ... 

dx = (unitless) physical size of a cell

boundary_XX = kind of boundary condition on a given border of the domain
	    1 = reflexion
	    2 = absorption
	    3 = periodic

testcase = one of the hard coded test cases (0 = center explosion, 1 =
corner explosion, 3 = sinus curve explosion)


_______________________________________________________________


When a runs reaches either nstepmax or its time limit and chkpt=1, a
file Continue.dump is produced.


When a runs reaches tend, a STOP file is created, preventing any
further runs. If you need to go further along the simulation, change
tend and remove this file.

The global environment variable BRIDGE_MPRUN_MAXTIME specifies the
maximum total ELAPS time of a run in seconds (defaul is 30 mn if not
set).


on an IvyBridge with 24cores, a nx=1000,ny=1000,tend=1 takes 7s
on an IvyBridge with 24cores, a nx=2000,ny=2000,tend=1 takes 22s

for a 2000x2000 testcase (testcase=0), useful results are obtained for
tend=1000 at least.

Warning: the VTK output can become rather huge (>> GB). It is written
in the current directory as a Dep folder. It is piloted by the
Hydro.pvd file. Use paraview (www.paraview.org) to post process the
results. Be careful that a 5000x5000 test case can exhaust all the
memory with paraview.


If your run has produced PNG images (e.g. tend=1000, dtimage=10), the
faitfilm script can be used to produce a movie of your computation
(requires mencoder [and mplayer]).

Enjoy.
Guillaume Colin de Verdiere

28/03/2014
updated 30/10/2017

